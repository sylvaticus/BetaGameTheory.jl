var documenterSearchIndex = {"docs":
[{"location":"api.html#Detailed-API","page":"API","title":"Detailed API","text":"","category":"section"},{"location":"api.html","page":"API","title":"API","text":"Modules = [StrategicGames]\nOrder   = [:constant, :type, :function, :macro]","category":"page"},{"location":"api.html#StrategicGames.Verbosity","page":"API","title":"StrategicGames.Verbosity","text":"Verbosity\n\nMany functions accept a verbosity parameter.\n\nChoose between: NONE, LOW, STD [default], HIGH and FULL.\n\nUnder default verbosity (STD) no output is printed, unless something unexpected in most conditions (but not necessarily an error) is detected \n\n\n\n\n\n","category":"type"},{"location":"api.html#StrategicGames.best_response-Tuple{Any, Any, Any}","page":"API","title":"StrategicGames.best_response","text":"best_response(payoff_array,strategy_profile,nplayer;solver)\n\nReturn (possibly one of many) best strategy and corrsponding expected payoff for a given player.\n\nParameters:\n\npayoff_array: the N_players+1 dimensional array of payoffs\nstrategy_profile: the vector of vectors defining the strategies for the N players. The strategy for player n for which the best response is computed is used as initial values in the inner optimisation\nnplayer: counter of the player for which we want to compute the best_response (e.g. 1 or 3)\nsolver: currently either \"GLPK\" or \"HiGHS\"\nverbosity: either NONE, LOW, STD [default], HIGH or FULL\n\nReturns:\n\nA named tuple with: expected_payoff, optimal_strategy, status (of the underlying optimisation)\n\nExample:\n\njulia> using StrategicGames\njulia> payoff_array  = [(3,4) (1,5); (4,2) (2,3)] # prisoner's dilemma\n2×2 Matrix{Tuple{Int64, Int64}}:\n (3, 4)  (1, 5)\n (4, 2)  (2, 3)\njulia> best_response(expand_dimensions(payoff_array),[[0.5,0.5],[0.5,0.5]],2)\n(expected_payoff = 4.0, optimal_strategy = [0.0, 1.0], status = MathOptInterface.OPTIMAL)\n\n\n\n\n\n","category":"method"},{"location":"api.html#StrategicGames.dominated_strategies-Tuple{Any}","page":"API","title":"StrategicGames.dominated_strategies","text":"dominated_strategies(payoff;strict=true,iterated=true,dominated,support,verbosity)\n\nImplements the \"Iterated [by default] Removal of Strictly [by default] Dominated Strategies\" (IRSDS) algorithm, returning a vector (for each player) of vectors (action positions) of actions that for a given player are dominates by at least one of his other actions. This function is iterative (recursive) by default.\n\nParameters\n\npayoff_array: the Nplayers+1 dimensional array of payoffs for the N players\nstrict: wheter to look for strictly dominated actions [def: true]\niterated: wheter to look for dominated actions iteractively [def: true]\ndominated: vector of vectors of actions to skip check as already deemed as dominated\nsupport: support profile to consider (vector of vectors, see notes). Default all actions\nverbosity: either NONE, LOW, STD [default], HIGH or FULL\n\nNotes\n\nThis function is available also as dominated_strategies(payoff,player;strict) returning a vector of dominated strategies for a given players (computed not iteractively)\nWhae a particolar support is specified, the function looks for dominated strategies within the support for a given player, but considering also for possibly dominating actions outside its support. In both cases only the actions in the supports of the other players are considered.\nTo get the list of retrieved dominated actions at each iteration, use a verbosity level higher than STD \n\nExample\n\njulia> using StrategicGames\njulia> payoff = [(13,3) (1,4) (7,3); (4,1) (3,3) (6,2); (-1,9) (2,8) (8,-1)]\n3×3 Matrix{Tuple{Int64, Int64}}:\n (13, 3)  (1, 4)  (7, 3)\n (4, 1)   (3, 3)  (6, 2)\n (-1, 9)  (2, 8)  (8, -1)\njulia> payoff_array = expand_dimensions(payoff);\njulia> dominated_player2 = dominated_strategies(payoff_array,2)\n1-element Vector{Int64}:\n 3\njulia> dominated = dominated_strategies(payoff_array,verbosity=HIGH)\nDominated strategies at step 1: [Int64[], [3]]\nDominated strategies at step 2: [[3], [3]]\nDominated strategies at step 3: [[3], [3, 1]]\nDominated strategies at step 4: [[3, 1], [3, 1]]\nDominated strategies at step 5: [[3, 1], [3, 1]]\n2-element Vector{Vector{Int64}}:\n [3, 1]\n [3, 1]\n\n\n\n\n\n","category":"method"},{"location":"api.html#StrategicGames.expand_dimensions-Union{Tuple{AbstractArray{T}}, Tuple{T}, Tuple{T2}} where {T2, T<:Tuple{Vararg{T2}}}","page":"API","title":"StrategicGames.expand_dimensions","text":"expand_dimensions(x::AbstractArray{T}\n\nConvenience function to transform a N dimensional array of tuples in a N+1 dimensional array of scalars (the format used for most functions in this package).\n\nExample:\n\njulia> using StrategicGames\njulia> payoff_tuple = [(1,-1) (-1,1) (1,0); (-1,1) (1, -1) (0,1)] # 2 players, with 2 and 3 actions respectively\n2×3 Matrix{Tuple{Int64, Int64}}:\n (1, -1)  (-1, 1)  (1, 0)\n (-1, 1)  (1, -1)  (0, 1)\n\njulia> payoff_array = expand_dimensions(payoff_tuple)\n2×3×2 Array{Int64, 3}:\n[:, :, 1] =\n  1  -1  1\n -1   1  0\n\n[:, :, 2] =\n -1   1  0\n  1  -1  1\n\n\n\n\n\n","category":"method"},{"location":"api.html#StrategicGames.expected_value-Tuple{Any, Any}","page":"API","title":"StrategicGames.expected_value","text":"expected_value(v::Array{N,Real},p::Vector{Vector{Real}}) --> Real\n\nCompute the expected value (scalar) of a N-dimensional value array given a vector of N probability vectors, one per each dimension of the value array. \n\n\n\n\n\n","category":"method"},{"location":"api.html#StrategicGames.is_best_response-Tuple{Any, Any, Any}","page":"API","title":"StrategicGames.is_best_response","text":"is_best_response(payoff_array,strategy_profile,nplayer;atol=1e-07,rtol=1e-07,solver,verbosity=STD)\n\nDetermine if a given strategy for player nplayer is a best response to a given payoff array and strategies of the other players\n\nParameters:\n\npayoff_array: the Nplayers+1 dimensional array of payoffs\nstrategy_profile: the vector of vectors defining the strategies for the N players\nnplayer: counter of the player for which we want to verify if its strategy is a best_response (e.g. 1 or 3)\natol: absolute tollerance in comparing the expected payoff from the given strategy and those from the optimal one [def: 1e-07]\nrtol: relative tollerance in comparing the expected payoff from the given strategy and those from the optimal one [def: 1e-07]\nsolver: currently either \"GLPK\" or \"HiGHS\"\nverbosity: either NONE, LOW, STD [default], HIGH or FULL\n\nExample :\n\njulia> using StrategicGames\njulia> payoff_array = [(3,4) (1,5); (4,2) (2,3)] # prisoner's dilemma\n2×2 Matrix{Tuple{Int64, Int64}}:\n (3, 4)  (1, 5)\n (4, 2)  (2, 3)\njulia> is_best_response(expand_dimensions(payoff_array),[[0,1],[0.5,0.5]],1)\ntrue\njulia> is_best_response(expand_dimensions(payoff_array),[[0,1],[0.5,0.5]],2)\nfalse\n\n\n\n\n\n","category":"method"},{"location":"api.html#StrategicGames.is_nash-Tuple{Any, Any}","page":"API","title":"StrategicGames.is_nash","text":"is_nash(payoff_array,strategy_profile;atol=1e-07,rtol=1e-07,solver,verbosity)\n\nDetermine if a strategy profile is a Nash equilibrium for a given payoff array, i.e. if all strategies are (at least weak) best responses.\n\nParameters:\n\npayoff_array: the Nplayers+1 array of payoffs\nstrategy_profile: the vector of vectors defining the strategies for the N players\natol: absolute tollerance in comparing the expected payoffs from the given strategies and those from the optimal ones [def: 1e-07]\nrtol: relative tollerance in comparing the expected payoffs from the given strategies and those from the optimal ones [def: 1e-07]\nsolver: currently either \"GLPK\" or \"HiGHS\"\nverbosity: either NONE, LOW, STD [default], HIGH or FULL\n\nExample :\n\njulia> using StrategicGames\njulia> payoff_array  = [(3,4) (1,5); (4,2) (2,3)] # prisoner's dilemma\n2×2 Matrix{Tuple{Int64, Int64}}:\n (3, 4)  (1, 5)\n (4, 2)  (2, 3)\njulia> is_nash(expand_dimensions(payoff_array),[[0,1],[0,1]])\ntrue\n\n\n\n\n\n","category":"method"},{"location":"api.html#StrategicGames.nash_cp-Tuple{Any}","page":"API","title":"StrategicGames.nash_cp","text":"nash_cp(payoff_array;init,verbosity)\n\nFind a Nash Equilibrium for N-players simultaneous games when mixed strategies are allowed using the Complementarity Problem formulation and implementing iterated removal of dominated strategies\n\nParameters\n\npayoff_array: the Nplayers+1 dimensional array of payoffs for the N players\ninit: a vector of vector of mixed strategies (i.e. PMFs) for each players to start the algorithm with. Different init points may reach different equilibrium points [def: equal probabilities for each available action of the players]\nstrict_domination_removal: wether to remove only strictly dominated strategies in the pre-optimisation or also weakly dominated ones [def: true]\nverbosity: either NONE, LOW, STD [default], HIGH or FULL\n\nNotes\n\nThis function uses a complementarity formulation. For N <= 2 the problem, except the complementarity equation, is linear and known as LCP (Linear Complementarity Problem)\nThis implementation uses the JuMP modelling language with the Ipopt solver engine (and hence it uses an interior point method instead of the pivotal approach used in the original Lemke-Howson [1964] algorithm)\nThere is no guarantee on timing and even that the algorithm converge to an equilibrium. Different Nash equilibriums may be reached by setting different initial points\nBy default the iterative removal of dominated strategies concerns only strictly dominated ones. For some games where the algorithm doesn't find a Nash equilibrium, you can often get success setting the algorithm to remove also weakly dominated strategies. \n\nReturns\n\nA named tuple with the following elements: status,equilibrium_strategies,expected_payoffs\n\nExample\n\njulia> using StrategicGames\njulia> payoff = [(-1,-1) (-3,0); (0, -3) (-2, -2)] # prisoner's dilemma\n2×2 Matrix{Tuple{Int64, Int64}}:\n (-1, -1)  (-3, 0)\n (0, -3)   (-2, -2)\njulia> eq     = nash_cp(expand_dimensions(payoff));\njulia> eq_strategies = eq.equilibrium_strategies\n2-element Vector{Vector{Float64}}:\n [-4.049752569180346e-11, 1.0000000000404976]\n [-4.0497525691839856e-11, 1.0000000000404976]\n\n\n\n\n\n","category":"method"},{"location":"api.html#StrategicGames.nash_on_support","page":"API","title":"StrategicGames.nash_on_support","text":"nash_on_support(payoff_array,support;init,verbosity)\n\nFind (if it exists) a Nash equilibrium for N-players simultaneous games when mixed strategies are allowed on a specific support.\n\nParameters\n\npayoff_array: the Nplayers+1 dimensional array of payoffs for the N players\nsupport: vector of vector of action counts that are in the tested support for each player [def: full support]\ninit: a vector of vector of mixed strategies (i.e. PMFs) for each players to start the algorithm with. Different init points may reach different equilibrium points [def: equal probabilities for each available action of the players]\nverbosity: either NONE, LOW, STD [default], HIGH or FULL\n\nNotes\n\nThis implementation uses the JuMP modelling language with the Ipopt solver engine\n\nReturns\n\nA named tuple with the following elements: status,equilibrium_strategies,expected_payoffs, solved\n\nExample\n\njulia> using StrategicGames\njulia> payoff = [(-1,-1) (-3,0); (0, -3) (-2, -2)] # prisoner's dilemma. Only Nash eq is [[0,1],[0,1]]\n2×2 Matrix{Tuple{Int64, Int64}}:\n (-1, -1)  (-3, 0)\n (0, -3)   (-2, -2)\njulia> payoff_array = expand_dimensions(payoff);\njulia> nash_on_support(payoff_array,[[1,2],[1,2]]).solved # false\nfalse\njulia> nash_on_support(payoff_array,[[2],[2]]).solved     # true\ntrue\n\n\n\n\n\n","category":"function"},{"location":"api.html#StrategicGames.nash_se-Tuple{Any}","page":"API","title":"StrategicGames.nash_se","text":"nash_se(payoff_array; allow_mixed=true, max_samples=1, verbosity=STD)\n\nCompute max_samples (default one) Nash equilibria for a N-players generic game in normal form using support enumeration method.\n\nParameters\n\npayoff_array: the Nplayers+1 dimensional array of payoffs for the N players\nallow_mixed: wether to look and report also mixed strategies (default) or look only for pure strategies (if any)\nmax_samples: number of found sample Nash equilibria needed to stop the algorithm [def: 1]. Set it to Inf to look for all the possible isolated equilibria of the game\nverbosity: either NONE, LOW, STD [default], HIGH or FULL\n\nNotes\n\nThis function uses a support enumeration method to avoid the complementarity conditions and solve simpler problems conditional to a specific support.  More specifically we use the heuristic of Porter-Nudelman-Shoham (2008) and a dominance check, altought not recursively as in  Turocy (2007)\nGiven enought computational resources, all isolated Nash equilibria that are unique for a given support should be returned by this function \n\nReturns\n\nA vector of named tuples (even for the default single max_samples) with the following information: equilibrium_strategies, expected_payoffs, supports \n\nExample\n\njulia> using StrategicGames\njulia> payoff = expand_dimensions([(3,3) (3,2);\n                                   (2,2) (5,6);\n                                   (0,3) (6,1)]);\njulia> eqs = nash_se(payoff,max_samples=Inf)\n3-element Vector{NamedTuple{(:equilibrium_strategies, :expected_payoffs, :supports), Tuple{Vector{Vector{Float64}}, Vector{Float64}, Vector{Vector{Int64}}}}}:\n (equilibrium_strategies = [[0.9999999999999999, 0.0, 0.0], [0.9999999999999999, 0.0]], expected_payoffs = [2.9999999999999516, 2.9999999999999516], supports = [[1], [1]])\n (equilibrium_strategies = [[0.8, 0.2, 0.0], [0.6666666666666666, 0.33333333333333337]], expected_payoffs = [3.0, 2.8000000000000003], supports = [[1, 2], [1, 2]])\n (equilibrium_strategies = [[0.0, 0.33333333333333337, 0.6666666666666666], [0.33333333333333315, 0.6666666666666669]], expected_payoffs = [4.000000000000001, 2.6666666666666665], supports = [[2, 3], [1, 2]])\n\n\n\n\n\n","category":"method"},{"location":"api.html#StrategicGames.nash_se2-Tuple{Any}","page":"API","title":"StrategicGames.nash_se2","text":"nash_se2(payoff; allow_mixed=true, max_samples=1, verbosity=STD)\n\nONLY FOR BENCHMARKS, UNEXPORTED Solves Nash eqs using support enumeration for 2 players game using strictly the approach of Porter-Nudelman-Shoham (2008)\n\n\n\n\n\n","category":"method"},{"location":"api.html#StrategicGames.unstack_payoff-Tuple{AbstractMatrix}","page":"API","title":"StrategicGames.unstack_payoff","text":"unstack_payoff(x::AbstractMatrix)\n\nUnstack a payoff encoded in long format, where the first half of the columns are the action positions for each player and the second half of the columns are the payoff for the various players, to the Nplayers+1 dimensional array used in the library.\n\nExample\n\njulia> # 2 players with 2 and 3 actions respectively\n       long_payoff = [\n            1 1 0.1 0.3;\n            1 2 4 6;\n            1 3 4 2;\n            2 2 4 5;\n            2 1 0.1 0.3;\n            2 3 1.3 2;];\njulia> unstack_payoff(long_payoff)\n2×3×2 Array{Float64, 3}:\n[:, :, 1] =\n 0.1  4.0  4.0\n 0.1  4.0  1.3\n[:, :, 2] =\n 0.3  6.0  2.0\n 0.3  5.0  2.0\n\n\n\n\n\n","category":"method"},{"location":"index.html#StrategicGames-package-documentation","page":"Index","title":"StrategicGames package documentation","text":"","category":"section"},{"location":"index.html","page":"Index","title":"Index","text":"GitHub repository","category":"page"},{"location":"index.html","page":"Index","title":"Index","text":"StrategicGames","category":"page"},{"location":"index.html#StrategicGames","page":"Index","title":"StrategicGames","text":"StrategicGames package\n\nStrategic Games provides functionalities to work with strategic games, including finding mixed or pure Nash equilibria in simultaneous games (currently nash_se, using support enumeration, and nash_cp solving the complementarity problem).\n\nUnless otherwise stated, all functions work with generic n players (the examples generally show 2 players for simplicity) and assume the payoff \"matrix\" to be in the form of N-players + 1 dimensional arrays, where each dimension except the last one is given by the number of discrete actions available to each player, while the last dimension is given by the number of players. Convenient functions (expand_dimensions and unstack_payoff) allows to transform payoff encoded in other form to the  N-players+1 dimensional array format used in this package.\n\n\n\n\n\n","category":"module"},{"location":"index.html#Index","page":"Index","title":"Index","text":"","category":"section"},{"location":"index.html","page":"Index","title":"Index","text":"StrategicGames provides the following functions:","category":"page"},{"location":"index.html","page":"Index","title":"Index","text":"Modules = [StrategicGames]\nOrder   = [:constant, :type, :function, :macro]","category":"page"},{"location":"index.html#examples","page":"Index","title":"Some examples","text":"","category":"section"},{"location":"index.html","page":"Index","title":"Index","text":"julia> using Pkg; Pkg.add(\"StrategicGames\") # only once to install the library\njulia> using StrategicGames","category":"page"},{"location":"index.html#players-game-with-payoff-a-function-of-the-number-of-players-choosing-the-same-option","page":"Index","title":"3-players game with payoff a function of the number of players choosing the same option","text":"","category":"section"},{"location":"index.html","page":"Index","title":"Index","text":"The 3 players in this game can choose between X or Y with payoffs respectively 2nₓ - 2nₓ²+3 and 4-nᵧ where nₓ and nᵧ represent the number of players that choose X or Y. (this example is taken from https://www.youtube.com/watch?v=bKrwQKUT0v8 where it is analytically solved)","category":"page"},{"location":"index.html","page":"Index","title":"Index","text":"julia> U = [(0,0,0) ; (3,3,3) ;; (3,3,3) ; (2,2,4) ;;;\n            (3,3,3) ; (2,4,2) ;; (4,2,2) ; (1,1,1) ;;;]\n2×2×2 Array{Tuple{Int64, Int64, Int64}, 3}:\n[:, :, 1] =\n (0, 0, 0)  (3, 3, 3)\n (3, 3, 3)  (2, 2, 4)\n[:, :, 2] =\n (3, 3, 3)  (4, 2, 2)\n (2, 4, 2)  (1, 1, 1)\njulia> payoff_array = expand_dimensions(U) # from n-dimensional array of tuples to n+1 arrays of scalars\n2×2×2×3 Array{Int64, 4}:\n[:, :, 1, 1] =\n 0  3\n 3  2\n[:, :, 2, 1] =\n 3  4\n 2  1\n[:, :, 1, 2] =\n 0  3\n 3  2\n[:, :, 2, 2] =\n 3  2\n 4  1\n[:, :, 1, 3] =\n 0  3\n 3  4\n[:, :, 2, 3] =\n 3  2\n 2  1\njulia> eq  = nash_cp(payoff_array)\n(status = MathOptInterface.LOCALLY_SOLVED, equilibrium_strategies = [[0.5811388300841898, 0.4188611699158103], [0.5811388300841898, 0.4188611699158103], [0.5811388300841898, 0.41886116991581035]], expected_payoffs = [2.16227766016838, 2.16227766016838, 2.16227766016838])\njulia> eq_strategies = eq.equilibrium_strategies\n3-element Vector{Vector{Float64}}:\n [0.5811388300841898, 0.4188611699158103]\n [0.5811388300841898, 0.4188611699158103]\n [0.5811388300841898, 0.41886116991581035]\njulia> p = -1 + sqrt(10)/2\n0.5811388300841898\njulia> eq_strategies ≈ [[p,1-p],[p,1-p],[p,1-p]]\ntrue\njulia> expected_payoff(payoff_array,eq_strategies)\n3-element Vector{Float64}:\n 2.1622776601683795\n 2.1622776601683795\n 2.1622776601683795","category":"page"},{"location":"index.html#Prisoner's-dilemma","page":"Index","title":"Prisoner's dilemma","text":"","category":"section"},{"location":"index.html","page":"Index","title":"Index","text":"julia> # Pay-off matrix\n       U = [(-1,-1) (-3,0); (0, -3) (-2, -2)]\n2×2 Matrix{Tuple{Int64, Int64}}:\n (-1, -1)  (-3, 0)\n (0, -3)   (-2, -2)\njulia> # From N-dimensional array of tuples to N+1 arrays of scalars    \n       payoff_array = expand_dimensions(U);\njulia> # Find all the dominated strategies for the two players\n       dominated_strategies(payoff_array)\n2-element Vector{Vector{Int64}}:\n [1]\n [1]\njulia> # Compute one Nash Equilibrium of the Game using LCP (linear complementarity) formulation       \n       eq = nash_cp(payoff_array).equilibrium_strategies\n2-element Vector{Vector{Float64}}:\n [-4.049752569180346e-11, 1.0000000000404976]\n [-4.0497525691839856e-11, 1.0000000000404976]\njulia> # Best response for player 2\n       best_response(payoff_array,[[0.5,0.5],[0.5,0.5]],2).optimal_strategy\n2-element Vector{Float64}:\n 0.0\n 1.0\njulia> # Expected payoffs given a specific strategy profile\n       expected_payoff(payoff_array,[[1,0],[1,0]])\n2-element Vector{Int64}:\n -1\n -1\njulia> # Is this strategy profile a Nash equilibrium ?\n       is_nash(payoff_array,[[1,0],[1,0]]) \nfalse","category":"page"},{"location":"index.html#Head-or-tail","page":"Index","title":"Head or tail","text":"","category":"section"},{"location":"index.html","page":"Index","title":"Index","text":"julia> payoff_matrix = [(1,-1) (-1,1); (-1,1) (1, -1)]\n2×2 Matrix{Tuple{Int64, Int64}}:\n (1, -1)  (-1, 1)\n (-1, 1)  (1, -1)\njulia> eq            = nash_cp(expand_dimensions(payoff_matrix));\njulia> eq_strategies = eq.equilibrium_strategies\n2-element Vector{Vector{Float64}}:\n [0.5, 0.5]\n [0.5, 0.5]","category":"page"},{"location":"index.html#Battle-of-the-sex","page":"Index","title":"Battle of the sex","text":"","category":"section"},{"location":"index.html","page":"Index","title":"Index","text":"julia> payoff_matrix = [(2,1) (0,0); (0,0) (1,2)]\n2×2 Matrix{Tuple{Int64, Int64}}:\n (2, 1)  (0, 0)\n (0, 0)  (1, 2)\njulia> eq            = nash_cp(expand_dimensions(payoff_matrix));\njulia> eq_strategies = eq.equilibrium_strategies \n2-element Vector{Vector{Float64}}:\n [0.6666666663602984, 0.33333333363970163]\n [0.33333333363970163, 0.6666666663602984]","category":"page"},{"location":"index.html","page":"Index","title":"Index","text":"\"Battle of the sex\" game has indeed 3 different equilibria. We can find them using the support enumeration method:","category":"page"},{"location":"index.html","page":"Index","title":"Index","text":"julia> eqs           = nash_se(expand_dimensions(payoff_matrix),max_samples=Inf);\njulia> eq_strategies = [eq.equilibrium_strategies for eq in eqs] \n3-element Vector{Vector{Vector{Float64}}}:\n [[0.9999999999999999, 0.0], [0.9999999999999999, 0.0]]\n [[0.0, 0.9999999999999999], [0.0, 0.9999999999999999]]\n [[0.6666666666666666, 0.33333333333333337], [0.3333333333333333, 0.6666666666666667]]\n ```\n\n#### Rock, paper, scissor","category":"page"},{"location":"index.html","page":"Index","title":"Index","text":"julia julia> # Actions: Rock, Paper, Scissor (in the order)        U = [(0,0) (-1,1) (1,-1); (1,-1) (0,0) (-1,1); (-1,1) (1,-1) (0,0) ] 3×3 Matrix{Tuple{Int64, Int64}}:  (0, 0)   (-1, 1)  (1, -1)  (1, -1)  (0, 0)   (-1, 1)  (-1, 1)  (1, -1)  (0, 0) julia> eq = nashcp(expanddimensions(U)).equilibrium_strategies 2-element Vector{Vector{Float64}}:  [0.3333333333333333, 0.3333333333333333, 0.3333333333333333]  [0.3333333333333333, 0.3333333333333333, 0.3333333333333333]","category":"page"},{"location":"index.html","page":"Index","title":"Index","text":"\n#### A biased penalty kick game\nThe row player is the kicker and the column player is the goalkeeper, first action is kick/jump on one direction, second one is kick/jump on the other direction.\nThe kicker is more efficient (or, alternatively, the goalkeeper is less efficient) on the second direction.\n","category":"page"},{"location":"index.html","page":"Index","title":"Index","text":"julia julia> payoffmatrix = [(-1,1) (1,-1); (1,-1) (0, 0)] 2×2 Matrix{Tuple{Int64, Int64}}:  (-1, 1)  (1, -1)  (1, -1)  (0, 0) julia> eq            = nashcp(expanddimensions(payoffmatrix)); julia> eqstrategies = eq.equilibriumstrategies 2-element Vector{Vector{Float64}}:  [0.3333333333332723, 0.6666666666667278]  [0.33333333333337, 0.6666666666666301] ```","category":"page"},{"location":"index.html#Acknowledgements","page":"Index","title":"Acknowledgements","text":"","category":"section"},{"location":"index.html","page":"Index","title":"Index","text":"The development of this package at the Bureau d'Economie Théorique et Appliquée (BETA, Nancy) was supported by the French National Research Agency through the Laboratory of Excellence ARBRE, a part of the “Investissements d'Avenir” Program (ANR 11 – LABX-0002-01).","category":"page"},{"location":"index.html","page":"Index","title":"Index","text":"(Image: BLogos)","category":"page"},{"location":"using_python_or_r.html#using_other_languages","page":"Using Python or R","title":"Using StrategicGames.jl from other programming languages","text":"","category":"section"},{"location":"using_python_or_r.html","page":"Using Python or R","title":"Using Python or R","text":"In this section we learn how to use StrategicGames in Python or R is almost as simple as to use a native library, with objects converted automatically between Julia and Python, and hence no specific package wrappers are needed. For Python we will show two separate \"Julia from Python\" interfaces, PyJulia and JuliaCall with the second one being the most recent one, while for R we will show the JuliaCall R package (no relations with the homonymous Python package).","category":"page"},{"location":"using_python_or_r.html#Use-StrategicGames-in-Python","page":"Using Python or R","title":"Use StrategicGames in Python","text":"","category":"section"},{"location":"using_python_or_r.html#With-the-classical-pyjulia-package","page":"Using Python or R","title":"With the classical pyjulia package","text":"","category":"section"},{"location":"using_python_or_r.html","page":"Using Python or R","title":"Using Python or R","text":"PyJulia is a relativelly old method to use Julia code and libraries in Python. It works great but it requires that you already have a Julia working installation on your PC, so we need first to download and install the Julia binaries for our operating system from JuliaLang.org. Be sure that Julia is working by opening the Julia terminal and e.g. typing println(\"hello world\")","category":"page"},{"location":"using_python_or_r.html","page":"Using Python or R","title":"Using Python or R","text":"Install PyJulia with: ","category":"page"},{"location":"using_python_or_r.html","page":"Using Python or R","title":"Using Python or R","text":"$ python3 -m pip install --user julia   # the name of the package in `pip` is `julia`, not `PyJulia`","category":"page"},{"location":"using_python_or_r.html","page":"Using Python or R","title":"Using Python or R","text":"We can now open a Python terminal and, to obtain an interface to Julia, just run:","category":"page"},{"location":"using_python_or_r.html","page":"Using Python or R","title":"Using Python or R","text":">>> import julia\n>>> julia.install() # Only once to set-up in julia the julia packages required by PyJulia\n>>> jl = julia.Julia(compiled_modules=False)","category":"page"},{"location":"using_python_or_r.html","page":"Using Python or R","title":"Using Python or R","text":"If we have multiple Julia versions, we can specify the one to use in Python passing julia=\"/path/to/julia/binary/executable\" (e.g. julia = \"/home/myUser/lib/julia-1.8.0/bin/julia\") to the install() function.","category":"page"},{"location":"using_python_or_r.html","page":"Using Python or R","title":"Using Python or R","text":"The compiled_module=False in the Julia constructor is a workaround to the common situation when the Python interpreter is statically linked to libpython, but it will slow down the interactive experience, as it will disable Julia packages pre-compilation, and every time we will use a module for the first time, this will need to be compiled first. Other, more efficient but also more complicate, workarounds are given in the package documentation, under the https://pyjulia.readthedocs.io/en/stable/troubleshooting.html[Troubleshooting section].","category":"page"},{"location":"using_python_or_r.html","page":"Using Python or R","title":"Using Python or R","text":"Let's now add to Julia the StrategicGames package. We can surely do it from within Julia, but we can also do it while remaining in Python:","category":"page"},{"location":"using_python_or_r.html","page":"Using Python or R","title":"Using Python or R","text":">>> jl.eval('using Pkg; Pkg.add(\"StrategicGames\")') # Only once to install StrategicGames","category":"page"},{"location":"using_python_or_r.html","page":"Using Python or R","title":"Using Python or R","text":"While jl.eval('some Julia code') evaluates any arbitrary Julia code (see below), most of the time we can use Julia in a more direct way. Let's start by importing the StrategicGames Julia package as a submodule of the Python Julia module:","category":"page"},{"location":"using_python_or_r.html","page":"Using Python or R","title":"Using Python or R","text":">>> from julia import StrategicGames\n>>> jl.seval(\"using StrategicGames\")","category":"page"},{"location":"using_python_or_r.html","page":"Using Python or R","title":"Using Python or R","text":"As you can see, it is no different than importing any other Python module.","category":"page"},{"location":"using_python_or_r.html","page":"Using Python or R","title":"Using Python or R","text":"For the data, let's load the payoff matrix \"Python side\" using Numpy:","category":"page"},{"location":"using_python_or_r.html","page":"Using Python or R","title":"Using Python or R","text":">>> import numpy as np\n>>> payoff = np.array([[[-1,-1],[-3,0]],[[0,-3],[-2,-2]]]) # prisoner's dilemma","category":"page"},{"location":"using_python_or_r.html","page":"Using Python or R","title":"Using Python or R","text":"We can now call StrategicGames functions as we would do for any other Python library functions. In particular, we can pass to the functions (and retrieve) complex data types without worrying too much about the conversion between Python and Julia types, as these are converted automatically:","category":"page"},{"location":"using_python_or_r.html","page":"Using Python or R","title":"Using Python or R","text":">>> eq = StrategicGames.nash_cp(payoff)\n>>> # Note that array indexing in Julia start at 1\n>>> eq\n<PyCall.jlwrap (status = MathOptInterface.LOCALLY_SOLVED, equilibrium_strategies = [[0.0, 0.9999999887780999], [0.0, 0.9999999887780999]], expected_payoffs = [-1.9999999807790678, -1.9999999807790678])\n>>> StrategicGames.is_nash(payoff,eq.equilibrium_strategies)\nTrue\n>>> StrategicGames.dominated_strategies(payoff)\n[array([1], dtype=int64), array([1], dtype=int64)]","category":"page"},{"location":"using_python_or_r.html","page":"Using Python or R","title":"Using Python or R","text":"Note: If we are using the jl.eval() interface, the objects we use must be already known to julia. To pass objects from Python to Julia, import the julia Main module (the root module in julia) and assign the needed variables, e.g.","category":"page"},{"location":"using_python_or_r.html","page":"Using Python or R","title":"Using Python or R","text":">>> X_python = [1,2,3,2,4]\n>>> from julia import Main\n>>> Main.X_julia = X_python\n>>> jl.eval('sum(X_julia)')\n12","category":"page"},{"location":"using_python_or_r.html","page":"Using Python or R","title":"Using Python or R","text":"Another alternative is to \"eval\" only the function name and pass the (python) objects in the function call:","category":"page"},{"location":"using_python_or_r.html","page":"Using Python or R","title":"Using Python or R","text":">>> jl.eval('sum')(X_python)\n12","category":"page"},{"location":"using_python_or_r.html#With-the-newer-JuliaCall-python-package","page":"Using Python or R","title":"With the newer JuliaCall python package","text":"","category":"section"},{"location":"using_python_or_r.html","page":"Using Python or R","title":"Using Python or R","text":"JuliaCall is a newer way to use Julia in Python that doesn't require separate installation of Julia.","category":"page"},{"location":"using_python_or_r.html","page":"Using Python or R","title":"Using Python or R","text":"Istall it in Python using pip as well:","category":"page"},{"location":"using_python_or_r.html","page":"Using Python or R","title":"Using Python or R","text":"$ python3 -m pip install --user juliacall","category":"page"},{"location":"using_python_or_r.html","page":"Using Python or R","title":"Using Python or R","text":"We can now open a Python terminal and, to obtain an interface to Julia, just run:","category":"page"},{"location":"using_python_or_r.html","page":"Using Python or R","title":"Using Python or R","text":">>> from juliacall import Main as jl","category":"page"},{"location":"using_python_or_r.html","page":"Using Python or R","title":"Using Python or R","text":"If you have julia on PATH, it will use that version, otherwise it will automatically download and install a private version for JuliaCall","category":"page"},{"location":"using_python_or_r.html","page":"Using Python or R","title":"Using Python or R","text":"If we have multiple Julia versions, we can specify the one to use in Python passing julia=\"/path/to/julia/binary/executable\" (e.g. julia = \"/home/myUser/lib/julia-1.8.0/bin/julia\") to the install() function.","category":"page"},{"location":"using_python_or_r.html","page":"Using Python or R","title":"Using Python or R","text":"To add StrategicGames to the JuliaCall private version we evaluate the julia package manager add function:","category":"page"},{"location":"using_python_or_r.html","page":"Using Python or R","title":"Using Python or R","text":">>> jl.seval('using Pkg; Pkg.add(\"StrategicGames\")') # Only once to install StrategicGames","category":"page"},{"location":"using_python_or_r.html","page":"Using Python or R","title":"Using Python or R","text":"As with PyJulia we can evaluate arbitrary Julia code either using jl.seval('some Julia code') and by direct call, but let's first import StrategicGames:","category":"page"},{"location":"using_python_or_r.html","page":"Using Python or R","title":"Using Python or R","text":">>> jl.seval(\"using StrategicGames\")\n>>> sg = jl.StrategicGames","category":"page"},{"location":"using_python_or_r.html","page":"Using Python or R","title":"Using Python or R","text":"For the data, we reuse the payoff Numpy arrays we created earlier.","category":"page"},{"location":"using_python_or_r.html","page":"Using Python or R","title":"Using Python or R","text":"We can now call StrategicGames functions as we would do for any other Python library functions. In particular, we can pass to the functions (and retrieve) complex data types without worrying too much about the conversion between Python and Julia types, as these are converted automatically:","category":"page"},{"location":"using_python_or_r.html","page":"Using Python or R","title":"Using Python or R","text":">>> eq = sg.nash_cp(payoff)\n>>> eq._jl_display() # force a \"Julian\" way of displaing of Julia objects\n(status = MathOptInterface.LOCALLY_SOLVED, equilibrium_strategies = [[0.0, 0.9999999887780999], [0.0, 0.9999999887780999]], expected_payoffs = [-1.9999999807790678, -1.9999999807790678])\n>>> sg.is_nash(payoff,eq.equilibrium_strategies)\nTrue\n>>> sg.dominated_strategies(payoff)\n<jl [[1], [1]]>\n","category":"page"},{"location":"using_python_or_r.html","page":"Using Python or R","title":"Using Python or R","text":"Note: If we are using the jl.eval() interface, the objects we use must be already known to julia. To pass objects from Python to Julia, we can write a small Julia macro:","category":"page"},{"location":"using_python_or_r.html","page":"Using Python or R","title":"Using Python or R","text":">>> X_python = [1,2,3,2,4]\n>>> jlstore = jl.seval(\"(k, v) -> (@eval $(Symbol(k)) = $v; return)\")\n>>> jlstore(\"X_julia\",X_python)\n>>> jl.seval(\"sum(X_julia)\")\n12","category":"page"},{"location":"using_python_or_r.html","page":"Using Python or R","title":"Using Python or R","text":"Another alternative is to \"eval\" only the function name and pass the (python) objects in the function call:","category":"page"},{"location":"using_python_or_r.html","page":"Using Python or R","title":"Using Python or R","text":">>> X_python = [1,2,3,2,4]\n>>> jl.seval('sum')(X_python)\n12","category":"page"},{"location":"using_python_or_r.html#Conclusions-about-using-StrategicGames-in-Python","page":"Using Python or R","title":"Conclusions about using StrategicGames in Python","text":"","category":"section"},{"location":"using_python_or_r.html","page":"Using Python or R","title":"Using Python or R","text":"Using either the direct call or the eval function, wheter in Pyjulia or JuliaCall, we should be able to use all the StrategicGames functionalities directly from Python. If you run into problems using StrategicGames from Python, open an issue specifying your set-up.","category":"page"},{"location":"using_python_or_r.html#Use-StrategicGames-in-R-(TODO)","page":"Using Python or R","title":"Use StrategicGames in R (TODO)","text":"","category":"section"},{"location":"using_python_or_r.html","page":"Using Python or R","title":"Using Python or R","text":"To use StrategicGames in R we start by installing the JuliaCall R package:","category":"page"},{"location":"using_python_or_r.html","page":"Using Python or R","title":"Using Python or R","text":"> install.packages(\"JuliaCall\")\n> library(JuliaCall)\n> julia_setup(installJulia = FALSE) # use installJulia = FALSE to let R download and install a private copy of julia","category":"page"},{"location":"using_python_or_r.html","page":"Using Python or R","title":"Using Python or R","text":"Note that, differently than PyJulia, the \"setup\" function needs to be called every time we start a new R section, not just when we install the JuliaCall package. If we don't have julia in the path of our system, or if we have multiple versions and we want to specify the one to work with, we can pass the JULIA_HOME = \"/path/to/julia/binary/executable/directory\" (e.g. JULIA_HOME = \"/home/myUser/lib/julia-1.1.0/bin\") parameter to the julia_setup call. Or just let JuliaCall automatically download and install a private copy of julia.","category":"page"},{"location":"using_python_or_r.html","page":"Using Python or R","title":"Using Python or R","text":"JuliaCall depends for some things (like object conversion between Julia and R) from the Julia RCall package. If we don't already have it installed in Julia, it will try to install it automatically.","category":"page"},{"location":"using_python_or_r.html","page":"Using Python or R","title":"Using Python or R","text":"As in Python, let's start from the data loaded from R and do some work with them in Julia:","category":"page"},{"location":"using_python_or_r.html","page":"Using Python or R","title":"Using Python or R","text":"> library(datasets)\n> X     <- as.matrix(sapply(iris[,1:4], as.numeric))\n> y     <- sapply(iris[,5], as.integer)\n> xsize <- dim(X)","category":"page"},{"location":"using_python_or_r.html","page":"Using Python or R","title":"Using Python or R","text":"Let's install StrategicGames. As we did in Python, we can install a Julia package from Julia itself or from within R:","category":"page"},{"location":"using_python_or_r.html","page":"Using Python or R","title":"Using Python or R","text":"> julia_eval('using Pkg; Pkg.add(\"StrategicGames\")')","category":"page"},{"location":"using_python_or_r.html","page":"Using Python or R","title":"Using Python or R","text":"We can now \"import\" the StrategicGames julia package (in julia a \"Package\" is basically a module plus some metadata that facilitate its discovery and integration with other packages, like the reuired set) and call its functions with the julia_call(\"juliaFunction\",args) R function:","category":"page"},{"location":"using_python_or_r.html","page":"Using Python or R","title":"Using Python or R","text":"> julia_eval(\"using StrategicGames\")\n> shuffled <- julia_call(\"consistent_shuffle\",list(X,y))\n> Xs       <- matrix(sapply(shuffled[1],as.numeric), nrow=xsize[1])\n> ys       <- as.vector(sapply(shuffled[2], as.integer))\n> m        <- julia_eval('KMeansClusterer(n_classes=3)')\n> yhat     <- julia_call(\"fit_ex\",m,Xs)\n> acc      <- julia_call(\"accuracy\",yhat,ys,ignorelabels=TRUE)\n> acc\n[1] 0.8933333","category":"page"},{"location":"using_python_or_r.html","page":"Using Python or R","title":"Using Python or R","text":"As alternative, we can embed Julia code directly in R using the julia_eval() function:","category":"page"},{"location":"using_python_or_r.html","page":"Using Python or R","title":"Using Python or R","text":"kMeansR  <- julia_eval('\n  function accFromKmeans(x,k,y)\n    m    = KMeansClusterer(n_classes=Int(k))\n    yhat = fit!(m,x)\n    acc  = accuracy(yhat,y,ignorelabels=true)\n    return acc\n  end\n')","category":"page"},{"location":"using_python_or_r.html","page":"Using Python or R","title":"Using Python or R","text":"We can then call the above function in R in one of the following three ways:","category":"page"},{"location":"using_python_or_r.html","page":"Using Python or R","title":"Using Python or R","text":"kMeansR(Xs,3,ys)\njulia_assign(\"Xs_julia\", Xs); julia_assign(\"ys_julia\", ys); julia_eval(\"accFromKmeans(Xs_julia,3,ys_julia)\")\njulia_call(\"accFromKmeans\",Xs,3,ys)","category":"page"},{"location":"using_python_or_r.html","page":"Using Python or R","title":"Using Python or R","text":"While other \"convenience\" functions are provided by the package, using  julia_call, or julia_assign followed by julia_eval, should suffix to use StrategicGames from R. If you run into problems using StrategicGames from R, open an issue specifying your set-up.","category":"page"},{"location":"using_python_or_r.html#dealing_with_stochasticity","page":"Using Python or R","title":"Dealing with stochasticity and reproducibility","text":"","category":"section"},{"location":"using_python_or_r.html","page":"Using Python or R","title":"Using Python or R","text":"Machine Learning workflows include stochastic components in several steps: in the data sampling, in the model initialisation and often in the models's own algorithms (and sometimes also in the prediction step). All StrategicGames models with a stochastic components support a rng parameter, standing for Random Number Generator. A RNG is a \"machine\" that streams a flow of random numbers. The flow itself however is deterministically determined for each \"seed\" (an integer number) that the RNG has been told to use. Normally this seed changes at each running of the script/model, so that stochastic models are indeed stochastic and their output differs at each run.","category":"page"},{"location":"using_python_or_r.html","page":"Using Python or R","title":"Using Python or R","text":"If we want to obtain reproductible results we can fix the seed at the very beginning of our model with Random.seed!([AnInteger]). Now our model or script will pick up a specific flow of random numbers, but this flow will always be the same, so that its results will always be the same.","category":"page"},{"location":"using_python_or_r.html","page":"Using Python or R","title":"Using Python or R","text":"However the default Julia RNG guarantee to provide the same flow of random numbers, conditional to the seed, only within minor versions of Julia. If we want to \"guarantee\" reproducibility of the results with different versions of Julia, or \"fix\" only some parts of our script, we can call the individual functions passing FIXEDRNG, an instance of StableRNG(FIXEDSEED) provided by StrategicGames, to the rng parameter. Use it with:","category":"page"},{"location":"using_python_or_r.html","page":"Using Python or R","title":"Using Python or R","text":"MyModel(;rng=FIXEDRNG)               : always produce the same sequence of results on each run of the script (\"pulling\" from the same rng object on different calls)\nMyModel(;rng=StableRNG(SOMEINTEGER)) : always produce the same result (new identical rng object on each call)","category":"page"},{"location":"using_python_or_r.html","page":"Using Python or R","title":"Using Python or R","text":"This is very convenient expecially during model development, as a model that use (...,rng=StableRNG(an_integer)) will provides stochastic results that are isolated (i.e. they don't depend from the consumption of the random stream from other parts of the model).","category":"page"},{"location":"using_python_or_r.html","page":"Using Python or R","title":"Using Python or R","text":"In particular, use rng=StableRNG(FIXEDSEED) or rng=copy(FIXEDRNG) with FIXEDSEED  to retrieve the exact output as in the documentation or in the unit tests.","category":"page"},{"location":"using_python_or_r.html","page":"Using Python or R","title":"Using Python or R","text":"Most of the stochasticity appears in training a model. However in few cases (e.g. decision trees with missing values) some stochasticity appears also in predicting new data using a trained model. In such cases the model doesn't restrict the random seed, so that you can choose at predict time to use a fixed or a variable random seed.","category":"page"},{"location":"using_python_or_r.html","page":"Using Python or R","title":"Using Python or R","text":"Finally, if you plan to use multiple threads and want to provide the same stochastic output independent to the number of threads used, have a look at generate_parallel_rngs.","category":"page"},{"location":"using_python_or_r.html","page":"Using Python or R","title":"Using Python or R","text":"\"Reproducible stochasticity\" is only one of the elements needed for a reproductible output. The other two are (a) the inputs the workflow uses and (b) the code that is evaluated. Concerning the second point Julia has a very modern package system that guarantee reproducible code evaluation (with a few exception linked to using external libraries, but StrategicGames models are all implemented in Julia itself). Without going in detail, you can use a pattern like this at the beginning of your machine learning workflows:","category":"page"},{"location":"using_python_or_r.html","page":"Using Python or R","title":"Using Python or R","text":"using Pkg  \ncd(@__DIR__)            \nPkg.activate(\".\")  # Activate a \"local\" environment, specific to this folder\nPkg.instantiate()  # Download and install the required packages if not already available ","category":"page"},{"location":"using_python_or_r.html","page":"Using Python or R","title":"Using Python or R","text":"This will tell Julia to load the exact version of dependent packages, and recursively of their dependencies, from a Manifest.toml file that is automatically created in the script's folder, and automatically updated, when you add or update a package in your workflow. Note that these locals \"environments\" are very \"cheap\" (packages are not actually copied to each environment on your system, only referenced) and the environment doen't need to be in the same script folder as in this example, can be any folder you want to \"activate\".","category":"page"},{"location":"using_python_or_r.html#Saving-and-loading-trained-models","page":"Using Python or R","title":"Saving and loading trained models","text":"","category":"section"},{"location":"using_python_or_r.html","page":"Using Python or R","title":"Using Python or R","text":"Trained models can be saved on disk using the model_save function, and retrieved with model_load. The advantage over the serialization functionality in Julia core is that the two functions are actually wrappers around equivalent JLD2 package functions, and should maintain compatibility across different Julia versions. ","category":"page"}]
}
